{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# URL de la sección de componentes de PC\n",
    "section_url = \"https://listado.mercadolibre.com.ar/componentes-de-pc#D[A:Componentes%20de%20PC]\" \n",
    "\n",
    "# Encabezados para evitar bloqueos\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept-Language': 'es-ES,es;q=0.9'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener enlaces de productos desde múltiples páginas de una misma seccion\n",
    "def get_product_links(base_url, num_pages=5):\n",
    "    product_links = []\n",
    "    for i in range(num_pages):\n",
    "        # Construir la URL para cada página\n",
    "        page_offset = i * 48\n",
    "        url = f\"{base_url}_Desde_{page_offset}_NoIndex_True\" if page_offset > 0 else base_url\n",
    "\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Buscar todos los enlaces de productos en la página actual\n",
    "        for a_tag in soup.find_all(\"a\", href=True):\n",
    "            href = a_tag[\"href\"]\n",
    "            # Filtrar enlaces que parecen productos\n",
    "            if \"mercadolibre.com.ar\" in href and \"/p/\" in href:\n",
    "                full_link = href.split(\"?\")[0]  # Limpiar parámetros adicionales\n",
    "                if full_link not in product_links:  # Evitar duplicados\n",
    "                    product_links.append(full_link)\n",
    "\n",
    "    return product_links\n",
    "\n",
    "# Función para clasificar el tipo de producto\n",
    "def classify_product_type(title):\n",
    "    title_lower = title.lower()\n",
    "    if \"procesador\" in title_lower:\n",
    "        return \"Procesador\"\n",
    "    elif \"ram\" in title_lower:\n",
    "        return \"RAM\"\n",
    "    elif \"placa de video\" in title_lower or \"tarjeta de video\" in title_lower or \"placa video\" in title_lower or \"tarjeta video\" in title_lower:\n",
    "        return \"Placa de Video\"\n",
    "    elif \"disco\" in title_lower or \"ssd\" in title_lower or \"hdd\" in title_lower:\n",
    "        return \"Disco\"\n",
    "    elif \"gabinete\" in title_lower:\n",
    "        return \"Gabinete\"\n",
    "    elif \"placa madre\" in title_lower or \"tarjeta madre\" in title_lower or \"motherboard\" in title_lower:\n",
    "        return \"Placa Madre\"\n",
    "    elif \"computadora\" in title_lower or \"pc\" in title_lower:\n",
    "        return \"Computadora\"\n",
    "    elif \"cooler\" in title_lower:\n",
    "        return \"Cooler\"\n",
    "    elif \"térmica\" in title_lower or \"pasta térmica\" in title_lower:\n",
    "        return \"Pasta Térmica\"\n",
    "    else:\n",
    "        return \"Otro\"\n",
    "\n",
    "# Función para extraer información de un producto desde la pagina de venta del producto\n",
    "def extract_product_data(URL):\n",
    "    # Realizar la solicitud a la página del producto\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Inicializar los datos del producto\n",
    "    product_data = {}\n",
    "\n",
    "    # Título del producto\n",
    "    try:\n",
    "        title = soup.find(\"h1\", class_=\"ui-pdp-title\").text.strip()\n",
    "        product_data['Title'] = title\n",
    "        # Clasificar el tipo de producto\n",
    "        product_data['Type'] = classify_product_type(title)\n",
    "    except AttributeError:\n",
    "        product_data['Title'] = \"NA\"\n",
    "        product_data['Type'] = \"NA\"\n",
    "\n",
    "    # Precio\n",
    "    try:\n",
    "        price = soup.find(\"span\", class_=\"andes-money-amount__fraction\").text.strip().replace(\".\", \"\")\n",
    "        product_data['Price'] = int(price)  # Convertir a entero\n",
    "    except AttributeError:\n",
    "        product_data['Price'] = \"NA\"\n",
    "\n",
    "    # Calificación\n",
    "    try:\n",
    "        rating = soup.find(\"span\", class_=\"ui-pdp-review__rating\").text.strip().replace(\".\", \",\")\n",
    "        product_data['Rating'] = rating  # Mantener como texto con coma\n",
    "    except AttributeError:\n",
    "        product_data['Rating'] = \"NA\"\n",
    "\n",
    "   # Número de opiniones\n",
    "    try:\n",
    "        reviews = soup.find(\"span\", class_=\"ui-pdp-review__amount\").text.strip(\"()\").replace(\".\", \"\")\n",
    "        product_data['Reviews'] = int(reviews)  # Convertir a entero\n",
    "    except AttributeError:\n",
    "        product_data['Reviews'] = \"NA\"\n",
    "\n",
    "   # Cantidad de productos vendidos\n",
    "    try:\n",
    "        sold_text = soup.find(\"span\", class_=\"ui-pdp-subtitle\").text.strip()\n",
    "        if \"vendidos\" in sold_text:\n",
    "            sold_number = (\n",
    "                sold_text.split(\"|\")[-1]\n",
    "                .replace(\"vendidos\", \"\")\n",
    "                .replace(\"+\", \"\")\n",
    "                .replace(\"mil\", \"000\")\n",
    "                .strip()\n",
    "            )\n",
    "            product_data['Sold'] = int(sold_number)\n",
    "        else:\n",
    "            product_data['Sold'] = \"NA\"\n",
    "    except AttributeError:\n",
    "        product_data['Sold'] = \"NA\"\n",
    "\n",
    "    return product_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 479 enlaces únicos.\n",
      "Datos guardados en 'productos_mercadolibre.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == '__main__':\n",
    "    # Obtener enlaces de productos de las primeras 5 páginas\n",
    "    num_pages = 10  # Cambia este valor para ajustar el número de páginas\n",
    "    product_links = get_product_links(section_url, num_pages=num_pages)\n",
    "    print(f\"Se encontraron {len(product_links)} enlaces únicos.\")\n",
    "    # Crear una lista para almacenar los datos de los productos\n",
    "    all_products = []\n",
    "    # Iterar sobre los enlaces y extraer datos\n",
    "    for link in product_links:\n",
    "        product_data = extract_product_data(link)\n",
    "        all_products.append(product_data)\n",
    "\n",
    "    # Crear un DataFrame y guardar como CSV\n",
    "    df = pd.DataFrame(all_products)\n",
    "    df.to_csv(\"productos_mercadolibre.csv\", index=False, encoding='utf-8-sig')\n",
    "    print(\"Datos guardados en 'productos_mercadolibre.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
